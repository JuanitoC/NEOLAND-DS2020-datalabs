{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides numerous tools to work with tabular data like you'd find in spreadsheets or databases. It is widely used for data preparation, cleaning, and analysis. It can work with a wide variety of data and provides many visualization options. It is built on top of NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rand_nums'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pandas uses something called a dataframe. It is a \n",
    "# 2D data structure that can hold multiple data types.\n",
    "# Columns have labels.\n",
    "\n",
    "# Series are built on top of NumPy arrays. \n",
    "# Create a series by first creating a list\n",
    "list_1 = ['a', 'b', 'c', 'd']\n",
    "# I can define that I want the series indexes to be the\n",
    "# provided labels\n",
    "labels = [1, 2, 3, 4]\n",
    "ser_1 = pd.Series(data=list_1, index=labels)\n",
    "\n",
    "# You can also add a NumPy array\n",
    "arr_1 = np.array([1, 2, 3, 4])\n",
    "ser_2 = pd.Series(arr_1)\n",
    "\n",
    "# You can quickly add labels and values with a dictionary\n",
    "dict_1 = {\"f_name\": \"Derek\", \n",
    "              \"l_name\": \"Banas\", \n",
    "              \"age\": 44}\n",
    "ser_3 = pd.Series(dict_1)\n",
    "\n",
    "# Get data by label\n",
    "ser_3[\"f_name\"]\n",
    "\n",
    "# You can get the datatype\n",
    "ser_2.dtype\n",
    "\n",
    "# You can perform math operations on series\n",
    "ser_2 + ser_2\n",
    "ser_2 - ser_2\n",
    "ser_2 * ser_2\n",
    "ser_2 / ser_2\n",
    "\n",
    "# You can pass them into NumPy methods\n",
    "# See NumPy tutorial for more math methods\n",
    "np.exp(ser_2)\n",
    "\n",
    "# The difference between Series and ndarray is that operations\n",
    "# align by labels\n",
    "# Create a series from a dictionary\n",
    "ser_4 = pd.Series({4: 5, 5: 6, 6: 7, 7: 8})\n",
    "# If labels don't align you will get NaN\n",
    "ser_2 + ser_4\n",
    "\n",
    "# You can assign names to series\n",
    "ser_4 = pd.Series({8: 9, 9: 10}, name='rand_nums')\n",
    "ser_4.name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames are the most commonly used data structure with Pandas. They are made up of multiple series that share the same index / label. They can contain multiple data types. They can be created from dicts, series, lists or other dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "# Create random matrix 2x3 with values between 10 and 50\n",
    "arr_2 = np.random.randint(10, 50, size=(2, 3))\n",
    "\n",
    "# Create DF with data, row labels & column labels\n",
    "df_1 = pd.DataFrame(arr_2, ['A', 'B'], ['C', 'D', 'E'])\n",
    "\n",
    "# Create a DF from multiple series in a dict\n",
    "# If series are of different lengthes extra spaces are NaN\n",
    "dict_3 = {'one': pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
    "         'two': pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "df_2 = pd.DataFrame(dict_3)\n",
    "df_2\n",
    "\n",
    "# from_dict accepts a column labels and lists\n",
    "pd.DataFrame.from_dict(dict([('A', [1,2,3]), ('B', [4,5,6])]))\n",
    "\n",
    "# You can assign the keys as row labels and column labels separate\n",
    "# with orient='index'\n",
    "pd.DataFrame.from_dict(dict([('A', [1,2,3]), ('B', [4,5,6])]),\n",
    "                      orient='index', columns=['one','two','three'])\n",
    "\n",
    "# Get number of rows and columns as tuple\n",
    "print(df_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing & Retrieving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    D   E\n",
      "A  34  25\n",
      "B  17  24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A\n",
       "0  1.0\n",
       "1  9.0\n",
       "2  3.0\n",
       "3  4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab a column\n",
    "df_1['C']\n",
    "# Get multiple columns\n",
    "df_1[['C', 'E']]\n",
    "\n",
    "# Grabb a row as a series\n",
    "df_1.loc['A']\n",
    "# Grab row by index position\n",
    "df_1.iloc[1]\n",
    "\n",
    "# Grab cell with Row & Column\n",
    "df_1.loc['A', 'C']\n",
    "# Grab multiple cells by defining rows wanted & the\n",
    "# columns from those rows\n",
    "print(df_1.loc[['A', 'B'], ['D', 'E']])\n",
    "\n",
    "# Make new column\n",
    "df_1['Total'] = df_1['C'] + df_1['D'] + df_1['E']\n",
    "df_1\n",
    "\n",
    "# You can perform multiple calculations\n",
    "df_2['mult'] = df_2['one'] * df_2['two']\n",
    "df_2\n",
    "\n",
    "# Make a new row by appending\n",
    "dict_2 = {'C': 44, 'D': 45, 'E': 46}\n",
    "new_row = pd.Series(dict_2, name='F')\n",
    "df_1 = df_1.append(new_row)\n",
    "\n",
    "# Delete column and set inplace to True which is required\n",
    "# because Pandas tries to help you not delete data\n",
    "# by accident\n",
    "df_1.drop('Total', axis=1, inplace=True)\n",
    "df_1\n",
    "# Delete a row\n",
    "df_1.drop('B', axis=0, inplace=True)\n",
    "df_1\n",
    "\n",
    "# Create a new column and make it the index\n",
    "df_1['Sex'] = ['Men', 'Women']\n",
    "df_1.set_index('Sex', inplace=True)\n",
    "\n",
    "# You can reset index values to numbers\n",
    "#df_1.reset_index(inplace=True)\n",
    "df_1\n",
    "\n",
    "# Assign can be used to create a column while leaving the\n",
    "# original DF untouched\n",
    "df_2.assign(div=df_2['one'] / df_2['two'])\n",
    "\n",
    "# You can pass in a function as well\n",
    "df_2.assign(div=lambda x: (x['one'] / x['two']))\n",
    "\n",
    "# Combine DataFrames while keeping df_3 data unless\n",
    "# there is a NaN value\n",
    "df_3 = pd.DataFrame({'A': [1., np.nan, 3., np.nan]})\n",
    "df_4 = pd.DataFrame({'A': [8., 9., 2., 4.]})\n",
    "df_3.combine_first(df_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    C   D   E\n",
      "A  14  16  18\n",
      "B  44  24  31\n",
      "Greater than 40\n",
      "        C      D      E\n",
      "A  False  False  False\n",
      "B   True  False  False\n",
      "Greater than 45\n",
      "        C      D      E\n",
      "A  False  False  False\n",
      "B  False  False  False\n",
      "B    44\n",
      "Name: C, dtype: int32\n",
      "\n",
      "    C   D\n",
      "B  44  24\n",
      "\n",
      "   X  Y  Z\n",
      "A  1  2  3\n",
      "B  4  5  6\n",
      "C  7  8  9 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X  Y  Z\n",
       "B  4  5  6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_2 = np.random.randint(10, 50, size=(2, 3))\n",
    "df_1 = pd.DataFrame(arr_2, ['A', 'B'], ['C', 'D', 'E'])\n",
    "print(df_1)\n",
    "\n",
    "# You can use conditional operators to retrieve a table\n",
    "# based on the condition\n",
    "print(\"Greater than 40\\n\", df_1 > 40.0)\n",
    "\n",
    "# You can use comparison operater functions as well like\n",
    "# gt, lt, ge, le, eq, ne\n",
    "print(\"Greater than 45\\n\", df_1.gt(45.0))\n",
    "\n",
    "# You can place conditions in brackets as well\n",
    "bool_1 = df_1 >= 45.0\n",
    "df_1[bool_1]\n",
    "\n",
    "# Get bools for a column\n",
    "df_1['E'] > 40\n",
    "\n",
    "# Return a row if cell value in column matches a condition\n",
    "df_1[df_1['E']>30]\n",
    "\n",
    "# You can focus on a column based on resulting dataframe\n",
    "df_2 = df_1[df_1['E']>30]\n",
    "df_2['C']\n",
    "\n",
    "# You can stack these commands\n",
    "print(df_1[df_1['E']>20]['C'])\n",
    "print()\n",
    "\n",
    "# You can also grab multiple columns\n",
    "print(df_1[df_1['E']>20][['C', 'D']])\n",
    "print()\n",
    "\n",
    "# You can use multiple conditions\n",
    "arr_3 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "df_2 = pd.DataFrame(arr_3, ['A', 'B', 'C'], ['X', 'Y', 'Z'])\n",
    "print(df_2, \"\\n\")\n",
    "# You can use or | to combine conditions as well\n",
    "df_2[(df_2['X']>3) & (df_2['X']<7)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Input / Output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can work with the following types of data : CSV, Plain Text, JSON, XML, PDF, SQL, HTML, XLSX, DOCX, ZIP, Images Hierarchical Data Format, MP3, and MP4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-102b4aaff801>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpymysql\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Read a CSV file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Type pd.read_ [TAB] to see the file types you can read\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcs_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ComputerSales.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymysql'"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "\n",
    "# Read a CSV file\n",
    "# Type pd.read_ [TAB] to see the file types you can read\n",
    "cs_df = pd.read_csv('ComputerSales.csv')\n",
    "\n",
    "# Save a CSV file, but don't save the index as a column\n",
    "cs_df.to_csv('ComputerSalesBU.csv', index=False)\n",
    "\n",
    "# You can read data from Excel, but not formulas and macros\n",
    "pd.read_excel('Financial Sample.xlsx',0)\n",
    "\n",
    "# Write to Excel\n",
    "cs_df.to_excel('ComputerSales.xlsx')\n",
    "\n",
    "# Check if written\n",
    "pd.read_excel('ComputerSales.xlsx',0)\n",
    "\n",
    "# Read from MySQL Database\n",
    "try:\n",
    "    db_connection = pymysql.connect(db='students', user='studentadmin', passwd='TurtleDove', host='localhost', port=3306)\n",
    "\n",
    "    stud_df = pd.read_sql('SELECT * FROM students', con=db_connection)\n",
    "    # print(stud_df)\n",
    "except Exception as e:\n",
    "    print(\"Exception : {}\".format(e))\n",
    "finally:\n",
    "    db_connection.close()\n",
    "    \n",
    "\n",
    "# Write to table \n",
    "try:\n",
    "    db_connection = pymysql.connect(db='students', user='studentadmin', passwd='TurtleDove', host='localhost', port=3306)\n",
    "    # Used to issue queries\n",
    "    cursor = db_connection.cursor()\n",
    "    # Query to enter new student\n",
    "    insert_stmt = \"INSERT INTO students VALUES(NULL, 'Frank', 'Silva', 'fsilva@aol.com', '666 Hell St', 'Yakima', 'WA', 98901, '792-223-8966', '1959-2-22', 'M', NOW(), 3.50)\"\n",
    "    # Execute query\n",
    "    cursor.execute(insert_stmt)\n",
    "    # Commit changes to DB\n",
    "    db_connection.commit()\n",
    "    stud_df = pd.read_sql('SELECT * FROM students', con=db_connection)\n",
    "    print(stud_df)\n",
    "except Exception as e:\n",
    "    print(\"Exception : {}\".format(e))\n",
    "finally:\n",
    "    db_connection.close()\n",
    "\n",
    "# Just get 1 column of data \n",
    "cs_df_st = pd.read_csv('ComputerSales.csv', usecols=[\"State\"], squeeze=True)\n",
    "cs_df_st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics & Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cs_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b3b6f7ee5d14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Display 1st 5 rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcs_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Display last 5 rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcs_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Get 1st 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cs_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Display 1st 5 rows\n",
    "cs_df.head()\n",
    "# Display last 5 rows\n",
    "cs_df.tail()\n",
    "# Get 1st 2\n",
    "cs_df[:2]\n",
    "# Get 1st through 5 with a 2 step\n",
    "cs_df[:5:2]\n",
    "\n",
    "# Get indexes\n",
    "cs_df.index.array\n",
    "# Get NumPy array\n",
    "cs_df.to_numpy()\n",
    "# Get array from series\n",
    "ser_1.array\n",
    "\n",
    "dict_3 = {'one': pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
    "         'two': pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "df_2 = pd.DataFrame(dict_3)\n",
    "\n",
    "# You can replace NaN values with 0 or anything else\n",
    "print(df_2.fillna(0))\n",
    "# Get values in row 2\n",
    "row = df_2.iloc[1]\n",
    "# Add items in row 2 to all rows including row 2\n",
    "# You can do the same with sub, mul, and div\n",
    "df_2.add(row, axis='columns')\n",
    "\n",
    "# Get column 2\n",
    "col = df_2['two']\n",
    "# Subtract from other columns\n",
    "df_2.sub(col, axis=0)\n",
    "\n",
    "# Check if empty\n",
    "df_2.empty\n",
    "\n",
    "# Transform executes a function on a dataframe\n",
    "df_5 = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
    "df_5.transform(lambda x: x+1)\n",
    "df_5.transform(lambda x: x**2)\n",
    "df_5.transform(lambda x: np.sqrt(x))\n",
    "# You can transform using multiple functions\n",
    "df_5.transform([lambda x: x**2, lambda x: x**3])\n",
    "# Passing a dictionary allows you to perform different calculations\n",
    "# on different columns\n",
    "df_5.transform({'A': lambda x: x**2, 'B': lambda x: x**3})\n",
    "\n",
    "# map performs a function on a series\n",
    "df_5['A'].map(lambda x: x**2)\n",
    "\n",
    "# applymap does the same on a dataframe\n",
    "df_5.applymap(lambda x: x**2)\n",
    "\n",
    "# Get unique values in column 2 of DF\n",
    "df_2['two'].unique()\n",
    "\n",
    "# Get number of uniques\n",
    "df_2['two'].nunique()\n",
    "\n",
    "# Get the number of times each value showed in column 2\n",
    "df_2['two'].value_counts()\n",
    "\n",
    "# Get column names\n",
    "df_2.columns\n",
    "\n",
    "# Get index info\n",
    "df_2.index\n",
    "\n",
    "# Return a DF that lists null values as True\n",
    "df_2.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sales                                              \n",
       "      count  mean       std   min   25%   50%   75%   max\n",
       "Store                                                    \n",
       "1       2.0  22.0  5.656854  18.0  20.0  22.0  24.0  26.0\n",
       "2       2.0  17.0  7.071068  12.0  14.5  17.0  19.5  22.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groupby allows you to group rows based on a columnand perform a function\n",
    "# that combines those values (Aggregate Function)\n",
    "dict_5 = {'Store': [1,2,1,2], 'Flavor': ['Choc', 'Van', 'Straw', 'Choc'], \n",
    "         'Sales': [26, 12, 18, 22]}\n",
    "\n",
    "df_11 = pd.DataFrame(dict_5)\n",
    "\n",
    "# Group data by the store number\n",
    "by_store = df_11.groupby('Store')\n",
    "# Get mean sales by store\n",
    "by_store.mean()\n",
    "\n",
    "# Get sales total just for store 1\n",
    "by_store.sum().loc[1]\n",
    "\n",
    "# You can use multiple functions of get a bunch\n",
    "by_store.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Merge & Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C     D\n",
       "1  1.0  4.0  7.0  10.0\n",
       "2  2.0  5.0  NaN   NaN\n",
       "3  3.0  6.0  NaN   NaN\n",
       "4  NaN  NaN  8.0  11.0\n",
       "5  NaN  NaN  9.0  12.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can concatenate DFs in the order DFs are provided\n",
    "df_12 = pd.DataFrame({'A': [1,2,3],\n",
    "                     'B': [4,5,6]},\n",
    "                    index=[1,2,3])\n",
    "df_13 = pd.DataFrame({'A': [7,8,9],\n",
    "                     'B': [10,11,12]},\n",
    "                    index=[4,5,6])\n",
    "pd.concat([df_12, df_13])\n",
    "\n",
    "# Merge 2 DFs using their shared key column\n",
    "df_12 = pd.DataFrame({'A': [1,2,3],\n",
    "                     'B': [4,5,6],\n",
    "                     'key': [1,2,3]})\n",
    "df_13 = pd.DataFrame({'A': [7,8,9],\n",
    "                     'B': [10,11,12],\n",
    "                     'key': [1,2,3]})\n",
    "# inner merges at the intersection of keys\n",
    "pd.merge(df_12, df_13, how='inner', on='key')\n",
    "# how='left' or 'right' : Use keys from left or right frame\n",
    "# how='outer' : Use union of keys\n",
    "\n",
    "# You can join DFs with different indexes and instead of using \n",
    "# keys use a column\n",
    "df_12 = pd.DataFrame({'A': [1,2,3],\n",
    "                     'B': [4,5,6]},\n",
    "                    index=[1,2,3])\n",
    "df_13 = pd.DataFrame({'C': [7,8,9],\n",
    "                     'D': [10,11,12]},\n",
    "                    index=[1,4,5])\n",
    "df_12.join(df_13, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X  Y  Z\n",
      "A  1  2  3\n",
      "B  4  5  6\n",
      "C  7  8  9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X    Y    Z\n",
       "mean  4.0  5.0  6.0\n",
       "std   3.0  3.0  3.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get ice cream sales data\n",
    "ics_df = pd.read_csv('icecreamsales.csv')\n",
    "ics_df\n",
    "\n",
    "# Get total count of both columns\n",
    "ics_df.count()\n",
    "\n",
    "# skipna skips null / NaN values\n",
    "ics_df.sum(skipna=True)\n",
    "# Get mean for named column\n",
    "ics_df[\"Sales\"].mean()\n",
    "ics_df[\"Sales\"].median()\n",
    "ics_df[\"Sales\"].mode()\n",
    "ics_df[\"Sales\"].min()\n",
    "ics_df[\"Sales\"].max()\n",
    "ics_df[\"Sales\"].prod() # Product of values\n",
    "ics_df[\"Sales\"].std() # Standard deviation\n",
    "ics_df[\"Sales\"].var() # Variance\n",
    "ics_df[\"Sales\"].sem() # Standard error\n",
    "# Negative : Left long tail, Positive : Right long tail\n",
    "ics_df[\"Sales\"].skew()\n",
    "# Kurtosis : < 3 less outliers, 3 Normal Distribution,\n",
    "# > 3 more outliers\n",
    "ics_df[\"Sales\"].kurt()\n",
    "ics_df[\"Sales\"].quantile(.5)\n",
    "ics_df[\"Sales\"].cumsum()\n",
    "ics_df[\"Sales\"].cumprod()\n",
    "ics_df[\"Sales\"].cummax()\n",
    "ics_df[\"Sales\"].cummin()\n",
    "\n",
    "# Multiple stats at once\n",
    "ics_df.describe()\n",
    "\n",
    "ser_dice = pd.Series(data=[2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, \n",
    "                           6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8,\n",
    "                          8, 8, 9, 9, 9, 9, 10, 10, 10, 11, 11, 12])\n",
    "# Count for each value in series\n",
    "ser_dice.value_counts()\n",
    "\n",
    "# You can perform calculations on multiple columns using\n",
    "# aggregate\n",
    "print(df_2)\n",
    "df_2.agg(np.mean)\n",
    "\n",
    "# You can do this with multiple functions\n",
    "df_2.agg(['mean', 'std'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "\n",
      "    C   D   E\n",
      "B  39  26  48\n",
      "C  33  21  12\n",
      "C\n",
      "B    39\n",
      "C    33\n",
      "Name: C, dtype: int32\n",
      "D\n",
      "B    26\n",
      "C    21\n",
      "Name: D, dtype: int32\n",
      "E\n",
      "B    48\n",
      "C    12\n",
      "Name: E, dtype: int32\n",
      "\n",
      "B\n",
      "C    39\n",
      "D    26\n",
      "E    48\n",
      "Name: B, dtype: int32\n",
      "C\n",
      "C    33\n",
      "D    21\n",
      "E    12\n",
      "Name: C, dtype: int32\n",
      "\n",
      "Pandas(Index='B', C=39, D=26, E=48)\n",
      "Pandas(Index='C', C=33, D=21, E=12)\n"
     ]
    }
   ],
   "source": [
    "# Iterating over series\n",
    "ser_7 = pd.Series(range(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "for col in ser_7:\n",
    "    print(col)\n",
    "    \n",
    "print()\n",
    "# Iterating over DFs\n",
    "arr_4 = np.random.randint(10, 50, size=(2, 3))\n",
    "df_8 = pd.DataFrame(arr_4, ['B', 'C'], ['C', 'D', 'E'])\n",
    "print(df_8)\n",
    "\n",
    "# items allows you to iterate through key value pairs to make\n",
    "# calculations 1 column at a time\n",
    "for label, ser in df_8.items():\n",
    "    print(label)\n",
    "    print(ser)\n",
    "    \n",
    "print()\n",
    "# You can also iterate through rows\n",
    "for index, row in df_8.iterrows():\n",
    "    print(f\"{index}\\n{row}\")\n",
    "print()\n",
    "\n",
    "# Get a tuple that contains row data\n",
    "for row in df_8.itertuples():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataFrame.items at 0x0EF261B0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_8\n",
    "\n",
    "# Sorting by index will return the same results if indexes\n",
    "# are in order, to reverse indexes mark ascending as False\n",
    "df_8.sort_index(ascending=False)\n",
    "\n",
    "# Sort by value for column D (Use the same function for series)\n",
    "df_8.sort_values(by='D')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing Data to Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cs_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c30cdc451796>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Total Profit : {prof_ser.sum()}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mget_profit_total\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcs_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Receives a DataFrame, splits the contact into new columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cs_df' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# You can pass DataFrames and Series into functions\n",
    "def get_profit_total(df):\n",
    "    prof_ser = df['Profit']\n",
    "    print(f\"Total Profit : {prof_ser.sum()}\")\n",
    "\n",
    "get_profit_total(cs_df)\n",
    "\n",
    "# Receives a DataFrame, splits the contact into new columns\n",
    "# being first and last name\n",
    "def split_name(df):\n",
    "    def get_names(full_name):\n",
    "        # Split contact at space\n",
    "        f_name, l_name = full_name.split()\n",
    "        # Create a series with first & last names in columns\n",
    "        # with those labels\n",
    "        return pd.Series(\n",
    "        (f_name, l_name),\n",
    "        index=['First Name', 'Last Name']\n",
    "        )\n",
    "    # apply() executes the function on all names in Contact column\n",
    "    names = df['Contact'].apply(get_names)\n",
    "    df[names.columns] = names\n",
    "    return df\n",
    "\n",
    "# Run function and display top 5 results\n",
    "split_name(cs_df).head()\n",
    "\n",
    "# Will assign people to different age groups based on age\n",
    "def create_age_groups(df):\n",
    "    # Must have 1 more bins than labels\n",
    "    bins = [0, 30, 50, sys.maxsize]\n",
    "    # Group labels\n",
    "    labels = ['<30', '30-50', '>50']\n",
    "    \n",
    "    # cut puts values into certain groups based on intervals\n",
    "    # The group assigned to <30 has an age between 0 and 30\n",
    "    # between 30 & 50 is assigned 30-50 and so on\n",
    "    age_group = pd.cut(df['Age'], bins=bins, labels=labels)\n",
    "    # Create new column and return new dataframe info\n",
    "    df['Age Group'] = age_group\n",
    "    return df\n",
    "\n",
    "create_age_groups(cs_df)\n",
    "\n",
    "# You can use a pipe to pass a dataframe to multiple functions\n",
    "cs_df.pipe(split_name).pipe(create_age_groups).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aligning, Reindexing and Renaming Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "d    3\n",
      "dtype: int64\n",
      "b    1\n",
      "c    2\n",
      "d    3\n",
      "e    4\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Pets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Men  Women  Pets\n",
       "1   43     38    49\n",
       "2   15     15    18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_6 = pd.Series(range(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "sl_1 = ser_6[:4]\n",
    "sl_2 = ser_6[1:]\n",
    "print(sl_1)\n",
    "print(sl_2)\n",
    "# Align both series by the union of their indexes\n",
    "sl_1.align(sl_2)\n",
    "# Align by calling series\n",
    "sl_1.align(sl_2, join='left')\n",
    "# Use passed series indexes\n",
    "sl_1.align(sl_2, join='right')\n",
    "# Get where indexes intersect\n",
    "sl_1.align(sl_2, join='inner')\n",
    "\n",
    "# You can use align with DFs as well\n",
    "arr_3 = np.random.randint(10, 50, size=(2, 3))\n",
    "df_6 = pd.DataFrame(arr_3, ['A', 'B'], ['C', 'D', 'E'])\n",
    "arr_3 = np.random.randint(10, 50, size=(2, 3))\n",
    "df_7 = pd.DataFrame(arr_3, ['B', 'C'], ['C', 'D', 'E'])\n",
    "df_6\n",
    "df_6.align(df_7)\n",
    "\n",
    "# reindex allows you to align data by index\n",
    "ser_6.reindex(['c','b','a'])\n",
    "\n",
    "# Do the same with DFs\n",
    "df_6.reindex(['B','A'])\n",
    "\n",
    "# Drop is very similar to reindex except it receives labels\n",
    "# you don't want to include\n",
    "df_6.drop(['A'], axis=0)\n",
    "df_6.drop(['D'], axis=1)\n",
    "\n",
    "# You can rename labels\n",
    "df_6.rename(columns={'C': 'Men', 'D': 'Women', 'E': 'Pets'},\n",
    "           index={'A': 1, 'B': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Day 1', 1), ('Day 1', 2), ('Day 1', 3), ('Day 2', 1), ('Day 2', 2), ('Day 2', 3)]\n",
      "           M    F\n",
      "Day 1 1  662  555\n",
      "      2  681  625\n",
      "      3  626  593\n",
      "Day 2 1  537  594\n",
      "      2  500  594\n",
      "      3  617  587\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Day 1</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Day 2</th>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "C          F    M\n",
       "A     B          \n",
       "Day 1 1  NaN  1.0\n",
       "      2  2.0  NaN\n",
       "      3  NaN  3.0\n",
       "Day 2 1  4.0  NaN\n",
       "      2  NaN  5.0\n",
       "      3  6.0  NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-level indexing allows you to store data on multiple\n",
    "# dimensions\n",
    "days = ['Day 1', 'Day 1', 'Day 1', 'Day 2', 'Day 2', 'Day 2']\n",
    "meals = [1,2,3,1,2,3]\n",
    "# zip pairs the days and meals arrays \n",
    "# Then we create a list of those paired tuples\n",
    "hier_index = list(zip(days, meals))\n",
    "print(hier_index)\n",
    "# Converts list of tuples into each row and column\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index)\n",
    "# Generate random array representing calories eaten per meal\n",
    "arr_5 = np.random.randint(500, 700, size=(6, 2))\n",
    "df_9 = pd.DataFrame(arr_5, hier_index, ['M', 'F'])\n",
    "print(df_9)\n",
    "\n",
    "# Grab the day 1 DF\n",
    "df_9.loc['Day 1']\n",
    "\n",
    "# Grab 1st row as a series\n",
    "df_9.loc['Day 1'].loc[1]\n",
    "\n",
    "# Grab calories eaten by the female on day 2 for the 2nd meal\n",
    "df_9.loc['Day 2'].loc[2]['F']\n",
    "\n",
    "# We can assign names to the Day and Meals Column\n",
    "df_9.index.names = ['Day', 'Meal']\n",
    "df_9\n",
    "\n",
    "# Get a cross section\n",
    "# This gets me the Day 2 DF\n",
    "df_9.xs('Day 2')\n",
    "\n",
    "# Get calories for the 1st meal for both days by saying what\n",
    "# meal index you want and the Meal column name\n",
    "df_9.xs(1, level='Meal')\n",
    "\n",
    "# Create a MultiIndex out of a DF using a pivot table\n",
    "dict_6 = {'A':['Day 1', 'Day 1', 'Day 1', 'Day 2', 'Day 2', 'Day 2'],\n",
    "         'B': [1,2,3,1,2,3],\n",
    "         'C': ['M', 'F', 'M', 'F', 'M', 'F'],\n",
    "         'D': [1,2,3,4,5,6]}\n",
    "df_14 = pd.DataFrame(dict_6)\n",
    "# Designate the D column is the data\n",
    "# Make A & B a multilevel index\n",
    "# Define column names come from column C\n",
    "# You will have NaNs where data was missing\n",
    "df_14.pivot_table(values='D', index=['A','B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "0  1.0  4.0  7.0\n",
      "1  2.0  NaN  8.0\n",
      "2  NaN  NaN  9.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C\n",
       "0  1.0  4.0  7.0\n",
       "1  2.0  NaN  8.0\n",
       "2  NaN  NaN  9.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_4 = {'A': [1,2,np.nan], 'B': [4, np.nan, np.nan], 'C': [7.,8.,9.]}\n",
    "df_10 = pd.DataFrame(dict_4)\n",
    "print(df_10)\n",
    "\n",
    "# Drop missing data from DF (Drops any row with missing values)\n",
    "df_10.dropna()\n",
    "\n",
    "# Drop all columns with any missing data\n",
    "df_10.dropna(axis=1)\n",
    "\n",
    "# Drop row unless it has at least 2 non-NaN values\n",
    "df_10.dropna(thresh=2)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df_10.fillna(value=0.0)\n",
    "\n",
    "# Fill A column with the mean of column\n",
    "df_10['A'].fillna(value=df_10['A'].mean())\n",
    "\n",
    "# Fill with previous value\n",
    "df_10.fillna(method='ffill')\n",
    "\n",
    "# Fill with next value (Only works if there is a next value)\n",
    "df_10.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cs_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-808b0ee8b0a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcs_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Get 1st 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcs_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Get column names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcs_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Profit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Average profit per item\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Get the product with the highest profit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcs_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Product ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Profit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cs_df' is not defined"
     ]
    }
   ],
   "source": [
    "cs_df.head() # Get 1st 5\n",
    "print(cs_df.columns) # Get column names\n",
    "cs_df['Profit'].mean() # Average profit per item\n",
    "# Get the product with the highest profit\n",
    "cs_df[['Product ID', 'Profit']].max(axis=0).head()\n",
    "# Number of people who purchased from WV\n",
    "cs_df[cs_df['State']=='WV']['State'].count()\n",
    "# Number of purchases in 2019\n",
    "len(cs_df[cs_df['Year']==2019].index)\n",
    "# Get number of sales for each product type\n",
    "cs_df['Product ID'].value_counts()\n",
    "# Get list of customers that bought a specific product\n",
    "cs_df[cs_df['Product ID']=='M01-F0024']['Contact']\n",
    "# How many made a website purchase for a profit over $200\n",
    "cs_df[(cs_df['Lead']=='Website') & (cs_df['Profit']>150)]['Lead'].count()\n",
    "# Find out how many product profit amounts include .89 in cents\n",
    "cs_df['Profit'].apply(lambda cents: str(cents).split('.')[1]=='89').value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Library usef to create advanced static, animated and\n",
    "# interactive visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Displays matplotlib plots in the Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Histograms provide an approximation of the distribution of\n",
    "# results. You create them by dividing the range of values into \n",
    "# bins or buckets. Then you count how many of the results fall\n",
    "# into each bin.\n",
    "# Rolls 2 dice 5000 times and charts the frequency and \n",
    "# a histogram\n",
    "\n",
    "# Even though the odds increase as you approach 7 and then\n",
    "# decrease again (1 way to roll a 2 / 6 ways to roll a 7)\n",
    "# over many rolls they are nearly equal.\n",
    "df_dice = pd.DataFrame(\n",
    "    np.random.randint(1,7,5000),\n",
    "    columns = ['Hist'])\n",
    "df_dice['Odds'] = df_dice['Hist'] + np.random.randint(1,7,5000)\n",
    "# Alpha decreases the opacity in the chart\n",
    "ax = df_dice.plot.hist(bins=12, alpha=0.5)\n",
    "\n",
    "# Basic plot using 1000 random values that create cumulative sums\n",
    "# over an increasing date range\n",
    "ser_5 = pd.Series(np.random.randn(1000),\n",
    "                 index=pd.date_range('11/15/2017', periods=1000))\n",
    "ser_5 = ser_5.cumsum()\n",
    "# ser_5.plot()\n",
    "\n",
    "# Display 3 random plots\n",
    "df_15 = pd.DataFrame(np.random.randn(1000, 3),\n",
    "                    index=pd.date_range('11/15/2017', periods=1000),\n",
    "                    columns=list('ABC'))\n",
    "df_15 = df_15.cumsum()\n",
    "# df_15.plot()\n",
    "\n",
    "# Make bar chart from 5 random values\n",
    "# pd.DataFrame(np.random.randn(5)).plot.bar()\n",
    "\n",
    "# Make MultiBar Charts\n",
    "vals = ['A', 'B', 'C', 'D']\n",
    "df_15 = pd.DataFrame(np.random.rand(10,4), columns=vals)\n",
    "# df_15.plot.bar()\n",
    "\n",
    "# Area plot \n",
    "# Define x range and y values\n",
    "x_rng = range(1,15)\n",
    "y_vals = [1,5,4,7,6,9,5,7,10,14,10,12,9,8]\n",
    "# Change fill color and opacity\n",
    "# plt.fill_between(x_rng, y_vals, color=\"skyblue\", alpha=0.5)\n",
    "# plt.show()\n",
    "\n",
    "# Area plot with multiple areas\n",
    "# pd.DataFrame(np.random.rand(10,3), columns=['A','B','C']).plot.area()\n",
    "\n",
    "# Create a scatterplot with 100 random values\n",
    "# pd.DataFrame(np.random.rand(100,2), \n",
    "#              columns=['A','B']).plot.scatter(x='A', y='B')\n",
    "\n",
    "# Multiple column scatter plots\n",
    "df_15 = pd.DataFrame(np.random.rand(50,4), columns=['A','B','C','D'])\n",
    "# ax = df_15.plot.scatter(x='A', y='B', color='DarkBlue', label='Grp 1')\n",
    "# df_15.plot.scatter(x='C', y='D', color='Orange', label='Grp 2', ax=ax)\n",
    "\n",
    "# Pie Charts with 4 random values\n",
    "# pd.Series(np.random.rand(4),\n",
    "#          index=['a','b','c','d'], \n",
    "#           name='Pie').plot.pie(figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
